#!/usr/bin/env python3
"""
Train Genesis on foundational texts and test query/synthesis.

This script:
1. Loads foundational texts from /usr/lib/alembic/data/datasets/text/curated/foundation/
2. Encodes them into core memory (foundation knowledge)
3. Queries the memory with test questions
4. Synthesizes responses and saves to ./output/
5. Verifies NO raw text is stored (only proto-identities)
"""

import os
import sys
from pathlib import Path
from datetime import datetime
import numpy as np

from src.pipeline.unified_encoder import UnifiedEncoder
from src.pipeline.unified_decoder import UnifiedDecoder
from src.memory.memory_hierarchy import MemoryHierarchy

# Ensure output directory exists
output_dir = Path("./output")
output_dir.mkdir(exist_ok=True)

print("=" * 80)
print("Genesis Foundation Training & Query Test")
print("=" * 80)

# Initialize Genesis
print("\n[1/5] Initializing Genesis Memory Hierarchy...")
memory = MemoryHierarchy(width=512, height=512, use_routing=True)
encoder = UnifiedEncoder(memory)
decoder = UnifiedDecoder(memory)
print(f"   ‚úì Memory hierarchy ready")

# Load foundational texts
foundation_dir = Path("/usr/lib/alembic/data/datasets/text/curated/foundation")
print(f"\n[2/5] Loading foundational texts from {foundation_dir}...")

# Select a few key texts (not all 42MB) - use SMALL samples for speed
foundation_texts = [
    "art_of_war_sun_tzu.txt",
    "tao_te_ching.txt"
]

total_chars = 0
total_texts_loaded = 0

for text_file in foundation_texts:
    filepath = foundation_dir / text_file
    if not filepath.exists():
        print(f"   ‚ö† Skipping {text_file} (not found)")
        continue

    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()[:2000]  # First 2k chars for faster demo

    print(f"   ‚Üí Encoding {text_file} ({len(content)} chars)...")
    result = encoder.encode(content, destination='core', octaves=[4, 0])

    total_chars += len(content)
    total_texts_loaded += 1

    print(f"      ‚úì {len(result.octave_units)} units ‚Üí core={result.core_added}, exp={result.experiential_added}")

print(f"\n   ‚úì Loaded {total_texts_loaded} foundational texts ({total_chars:,} chars)")
print(f"   ‚úì Core memory: {len(memory.core_memory.entries)} proto-identities")
print(f"   ‚úì Experiential memory: {len(memory.experiential_memory.entries)} proto-identities")

# Verify NO raw text stored
print(f"\n[3/5] Verifying ZERO raw data storage...")
violations = []
for entry in memory.core_memory.entries:
    # Check proto-identity is numerical
    if not isinstance(entry.proto_identity, np.ndarray):
        violations.append(f"Proto-identity not ndarray: {type(entry.proto_identity)}")

    # Check metadata has no raw content
    if 'content' in entry.metadata or ('text' in entry.metadata and len(entry.metadata.get('text', '')) > 20):
        violations.append(f"Metadata contains content: {list(entry.metadata.keys())}")

if violations:
    print(f"   ‚ùå VIOLATIONS FOUND:")
    for v in violations[:10]:
        print(f"      - {v}")
    sys.exit(1)
else:
    print(f"   ‚úì VERIFIED: All {len(memory.core_memory.entries)} entries contain ONLY proto-identities")
    print(f"   ‚úì NO raw text in metadata (only modality, octave, timestamp)")

# Query with test questions
print(f"\n[4/5] Querying foundational knowledge...")

test_queries = [
    "What is the art of war?",
    "How should a leader govern?",
    "What is virtue?",
    "What is the way of the Tao?"
]

query_results = []

for i, query in enumerate(test_queries, 1):
    print(f"\n   Query {i}: '{query}'")

    # Encode query
    query_encoding = encoder.encode(query, destination='experiential', octaves=[4, 0])
    print(f"      ‚Üí Encoded to {len(query_encoding.octave_units)} units")

    # Decode (retrieve from memory)
    if query_encoding.octave_units:
        response = decoder.decode(
            query_encoding.octave_units[0].proto_identity,
            layers='both',
            octaves=[4, 0, -2]
        )

        print(f"      ‚Üí Synthesis: '{response.text[:100]}...'")

        query_results.append({
            'query': query,
            'synthesis': response.text,
            'retrieved_count': 'N/A'
        })
    else:
        print(f"      ‚ö† No units to decode")

# Save trained model
print(f"\n[5/6] Saving trained foundation model...")

model_dir = Path("./models")
model_dir.mkdir(exist_ok=True)

timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
core_model_path = model_dir / f"genesis_foundation_core_{timestamp}.pkl"
exp_model_path = model_dir / f"genesis_foundation_exp_{timestamp}.pkl"

memory.core_memory.save(str(core_model_path))
memory.experiential_memory.save(str(exp_model_path))

print(f"   ‚úì Core memory saved: {core_model_path}")
print(f"   ‚úì Experiential memory saved: {exp_model_path}")
print(f"   ‚úì Model size: {core_model_path.stat().st_size / (1024**2):.1f} MB (core) + {exp_model_path.stat().st_size / (1024**2):.1f} MB (exp)")

# Save results to output
print(f"\n[6/6] Saving synthesis results to ./output/...")

output_file = output_dir / f"foundation_query_results_{timestamp}.txt"

with open(output_file, 'w', encoding='utf-8') as f:
    f.write("=" * 80 + "\n")
    f.write("Genesis Foundation Knowledge Query Results\n")
    f.write("=" * 80 + "\n\n")

    f.write(f"Timestamp: {datetime.now().isoformat()}\n")
    f.write(f"Foundational texts loaded: {total_texts_loaded}\n")
    f.write(f"Total characters encoded: {total_chars:,}\n")
    f.write(f"Core memory entries: {len(memory.core_memory.entries)}\n")
    f.write(f"Experiential memory entries: {len(memory.experiential_memory.entries)}\n")
    f.write("\n" + "=" * 80 + "\n\n")

    for i, result in enumerate(query_results, 1):
        f.write(f"Query {i}: {result['query']}\n")
        f.write(f"Synthesis:\n{result['synthesis']}\n")
        f.write("\n" + "-" * 80 + "\n\n")

print(f"   ‚úì Results saved to: {output_file}")

# Final summary
print("\n" + "=" * 80)
print("FOUNDATION TRAINING & QUERY: COMPLETE")
print("=" * 80)
print(f"‚úì Foundation texts encoded: {total_texts_loaded}")
print(f"‚úì Proto-identities in core memory: {len(memory.core_memory.entries)}")
print(f"‚úì Test queries executed: {len(query_results)}")
print(f"‚úì ZERO raw data storage: VERIFIED")
print(f"‚úì Model saved to: ./models/genesis_foundation_*_{timestamp}.pkl")
print(f"‚úì Results saved to: {output_file}")
print("=" * 80)
print("\nüéâ Genesis can store foundational knowledge, save trained models, and synthesize responses!")
